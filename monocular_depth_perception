<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>MiDaS Depth Live</title>
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<style>
body { margin:0; background:black; overflow:hidden; }
video, canvas {
  position:absolute;
  top:0;
  left:0;
}
#video {
  opacity:0.3; /* faint camera underneath depth */
}
</style>
</head>

<body>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

let session;

// ---------------- Camera Setup ----------------
async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({ video:true });
  video.srcObject = stream;
  return new Promise(resolve => {
    video.onloadedmetadata = () => {
      video.play();
      resolve();
    };
  });
}

// ---------------- Load ONNX Model ----------------
async function loadModel() {
  session = await ort.InferenceSession.create("./midas.onnx", {
    executionProviders:["wasm"]
  });
  console.log("Model loaded");
  console.log("Input names:", session.inputNames);
  console.log("Output names:", session.outputNames);
}

// ---------------- Preprocess Webcam Frame ----------------
function preprocess() {
  const size = 256;
  const inputCanvas = document.createElement("canvas");
  inputCanvas.width = size;
  inputCanvas.height = size;
  const ictx = inputCanvas.getContext("2d");
  ictx.drawImage(video, 0, 0, size, size);
  const imageData = ictx.getImageData(0, 0, size, size);
  const data = imageData.data;
  const floatData = new Float32Array(1*3*size*size);

  for (let i=0;i<size*size;i++){
    floatData[i] = data[i*4]/255.0;
    floatData[i+size*size] = data[i*4+1]/255.0;
    floatData[i+2*size*size] = data[i*4+2]/255.0;
  }

  return new ort.Tensor("float32", floatData, [1,3,size,size]);
}

// ---------------- Render Depth ----------------
function renderDepth(depthData, width, height){
  width = Number(width);
  height = Number(height);

  canvas.width = width;
  canvas.height = height;

  const imageData = ctx.createImageData(width,height);

  let min = Infinity;
  let max = -Infinity;
  for (let i=0;i<depthData.length;i++){
    if(depthData[i]<min) min=depthData[i];
    if(depthData[i]>max) max=depthData[i];
  }
  const range = max - min || 1;

  for(let i=0;i<width*height;i++){
    const normalized = (depthData[i]-min)/range;
    const value = Math.floor(normalized*255);
    imageData.data[i*4] = value;
    imageData.data[i*4+1] = value;
    imageData.data[i*4+2] = value;
    imageData.data[i*4+3] = 255;
  }

  ctx.putImageData(imageData,0,0);
}

// ---------------- Inference Loop ----------------
async function run(){
  const inputTensor = preprocess();
  const inputName = session.inputNames[0];
  const feeds = {};
  feeds[inputName] = inputTensor;

  const results = await session.run(feeds);

  const outputName = session.outputNames[0];
  const outputTensor = results[outputName];

  const depthData = outputTensor.data;
  const [batch, height, width] = outputTensor.dims;
  renderDepth(depthData,width,height);

  requestAnimationFrame(run);
}

// ---------------- Main ----------------
async function main(){
  await setupCamera();
  await loadModel();
  run();
}

main();
</script>
</body>
</html>
