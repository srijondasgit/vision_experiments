<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>Digital Display OCR</title>
<script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>
<style>
  *, *::before, *::after { box-sizing: border-box; }

  html, body {
    margin: 0; padding: 0;
    width: 100%; max-width: 100%;
    overflow-x: hidden;
  }

  body {
    background: #0a0a0a;
    color: #00ff88;
    font-family: 'Courier New', monospace;
    height: 100dvh;
    height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  h2 {
    flex-shrink: 0;
    font-size: 0.8rem;
    letter-spacing: 0.2em;
    text-transform: uppercase;
    margin: 10px 0 6px;
    opacity: 0.5;
  }

  /* Start screen */
  #start-screen {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    width: 100%;
    gap: 16px;
  }

  #start-screen p {
    opacity: 0.4;
    font-size: 0.75rem;
    letter-spacing: 0.08em;
    text-align: center;
    margin: 0 24px;
    line-height: 1.6;
  }

  #btn-start {
    padding: 18px 36px;
    font-size: 1rem;
    letter-spacing: 0.15em;
    border: 2px solid #00ff88;
    background: transparent;
    color: #00ff88;
    font-family: 'Courier New', monospace;
    cursor: pointer;
    border-radius: 6px;
    text-transform: uppercase;
    -webkit-tap-highlight-color: transparent;
    animation: pulse 2s infinite;
  }

  @keyframes pulse {
    0%, 100% { box-shadow: 0 0 0 0 #00ff8855; }
    50%       { box-shadow: 0 0 14px 4px #00ff8800; }
  }

  /* Camera wrapper - use 100% not 100vw to avoid Safari horizontal bleed */
  #cam-wrapper {
    display: none;
    position: relative;
    width: 100%;
    max-width: 480px;
    flex-shrink: 1;
    overflow: hidden;
    background: #000;
  }

  #video {
    display: block;
    width: 100%;
    height: 100%;
    object-fit: cover;
    background: #000;
  }

  #overlay {
    position: absolute;
    top: 0; left: 0;
    width: 100%; height: 100%;
    pointer-events: auto;
    touch-action: none;
  }

  /* Controls */
  #controls {
    display: none;
    flex-shrink: 0;
    flex-direction: row;
    gap: 8px;
    padding: 8px 12px;
    width: 100%;
    max-width: 480px;
  }

  button {
    flex: 1;
    padding: 9px 4px;
    background: transparent;
    border: 1px solid #00ff88;
    color: #00ff88;
    font-family: 'Courier New', monospace;
    font-size: 0.68rem;
    letter-spacing: 0.08em;
    text-transform: uppercase;
    cursor: pointer;
    border-radius: 4px;
    transition: background 0.15s;
    -webkit-tap-highlight-color: transparent;
    white-space: nowrap;
    overflow: hidden;
  }

  button:active, button.active { background: #00ff8833; }

  /* Output */
  #output-box {
    flex-shrink: 0;
    width: 100%;
    max-width: 480px;
    padding: 8px 14px 14px;
    border-top: 1px solid #00ff8820;
  }

  #status {
    font-size: 0.65rem;
    opacity: 0.45;
    margin-bottom: 3px;
    min-height: 1em;
  }

  #status.error { color: #ff4444; opacity: 1; }

  #output {
    font-size: 1.3rem;
    font-weight: bold;
    color: #00ff88;
    min-height: 1.8rem;
    word-break: break-all;
  }

  #selected {
    margin-top: 5px;
    font-size: 0.9rem;
    color: #ffff00;
    min-height: 1.3rem;
  }

  #canvas { display: none; }

  .scanning #status::after {
    content: '';
    animation: dots 1.2s infinite;
  }
  @keyframes dots {
    0%   { content: '.'; }
    33%  { content: '..'; }
    66%  { content: '...'; }
  }
</style>
</head>
<body>

<h2>Display OCR</h2>

<!-- Tap-to-start splash.
     Android Chrome BLOCKS getUserMedia called on page load without a
     real user gesture — this button provides that gesture. -->
<div id="start-screen">
  <button id="btn-start" onclick="handleStart()">TAP TO START CAMERA</button>
  <p>Point your rear camera at a digital display to read numbers.<br>Allow camera access when prompted.</p>
</div>

<!-- Hidden until camera starts -->
<div id="cam-wrapper">
  <video id="video" autoplay playsinline muted></video>
  <canvas id="overlay"></canvas>
</div>

<div id="controls">
  <button id="btn-torch" onclick="toggleTorch()">&#9889; Torch</button>
  <button id="btn-cam"   onclick="switchCamera()">&#8617; Flip</button>
  <button id="btn-pause" onclick="togglePause()">&#9208; Pause</button>
</div>

<div id="output-box">
  <div id="status">Tap the button above to begin.</div>
  <div id="output"></div>
  <div id="selected"></div>
</div>

<canvas id="canvas"></canvas>

<script>
  const video       = document.getElementById('video');
  const overlay     = document.getElementById('overlay');
  const ctxOv       = overlay.getContext('2d');
  const canvas      = document.getElementById('canvas');
  const ctx         = canvas.getContext('2d');
  const wrapper     = document.getElementById('cam-wrapper');
  const statusEl    = document.getElementById('status');
  const outputEl    = document.getElementById('output');
  const selectedEl  = document.getElementById('selected');
  const startScreen = document.getElementById('start-screen');
  const controls    = document.getElementById('controls');

  let boxes         = [];
  let processing    = false;
  let paused        = false;
  let currentStream = null;
  let torchOn       = false;
  let usingRear     = true;
  let ocrInterval   = null;
  let torchTrack    = null;
  let started       = false;

  // Entry point — MUST be called from a real user tap on Android
  async function handleStart() {
    if (started) return;
    started = true;
    startScreen.style.display = 'none';
    wrapper.style.display  = 'block';
    controls.style.display = 'flex';
    await startCamera(true);
  }

  // Camera
  async function startCamera(rear) {
    statusEl.className   = '';
    statusEl.textContent = 'Starting camera...';

    if (currentStream) {
      currentStream.getTracks().forEach(t => t.stop());
      currentStream = null;
    }

    // Layered fallback: { exact } first (gives best results on Android),
    // then { ideal }, then plain { video: true }.
    // We never mix resolution hints with facingMode in the same attempt
    // because Android Chrome rejects the whole request if any part fails.
    const attempts = rear ? [
      { video: { facingMode: { exact: 'environment' } }, audio: false },
      { video: { facingMode: { ideal: 'environment' } }, audio: false },
      { video: true, audio: false }
    ] : [
      { video: { facingMode: { exact: 'user' } }, audio: false },
      { video: { facingMode: { ideal: 'user' } }, audio: false },
      { video: true, audio: false }
    ];

    let lastError = null;
    for (const c of attempts) {
      try {
        currentStream = await navigator.mediaDevices.getUserMedia(c);
        lastError = null;
        break;
      } catch (e) {
        lastError = e;
        console.warn('getUserMedia failed:', e.name, e.message);
      }
    }

    if (!currentStream) {
      statusEl.className = 'error';
      if (lastError && lastError.name === 'NotAllowedError') {
        statusEl.textContent =
          'Permission denied. Open browser Settings > Site Settings > Camera, allow this site, then reload.';
      } else if (lastError && lastError.name === 'NotFoundError') {
        statusEl.textContent = 'No camera found on this device.';
      } else {
        statusEl.textContent = 'Camera error: ' + (lastError ? lastError.message : 'unknown');
      }
      return;
    }

    video.srcObject = currentStream;

    // Torch detection
    torchTrack = null;
    const vTrack = currentStream.getVideoTracks()[0];
    if (vTrack && typeof vTrack.getCapabilities === 'function') {
      try {
        const caps = vTrack.getCapabilities();
        if (caps.torch) torchTrack = vTrack;
      } catch(e) {}
    }

    // Wait for video ready + play
    await new Promise(resolve => {
      const go = async () => {
        try { await video.play(); } catch(e) {}
        resolve();
      };
      if (video.readyState >= 1) { go(); return; }
      video.addEventListener('loadedmetadata', go, { once: true });
    });

    // Let dimensions settle
    await new Promise(r => requestAnimationFrame(r));
    await new Promise(r => requestAnimationFrame(r));

    syncSizes();
    statusEl.textContent = 'Scanning';
    document.body.classList.add('scanning');
    startOCRLoop();
  }

  // Fit video wrapper height to video aspect ratio, but cap it
  // so controls + output always stay visible on screen.
  function syncSizes() {
    const vw = video.videoWidth  || 640;
    const vh = video.videoHeight || 480;
    const displayW = wrapper.offsetWidth || window.innerWidth;
    let   displayH = Math.round(displayW * vh / vw);
    const maxH     = Math.max(80, window.innerHeight - 130);
    if (displayH > maxH) displayH = maxH;

    wrapper.style.height = displayH + 'px';
    video.style.height   = displayH + 'px';
    overlay.width        = displayW;
    overlay.height       = displayH;
    canvas.width         = vw;
    canvas.height        = vh;
  }

  function switchCamera() {
    usingRear = !usingRear;
    torchOn   = false;
    document.getElementById('btn-torch').classList.remove('active');
    startCamera(usingRear);
  }

  async function toggleTorch() {
    if (!torchTrack) {
      statusEl.textContent = 'Torch not available on this camera.';
      return;
    }
    torchOn = !torchOn;
    try {
      await torchTrack.applyConstraints({ advanced: [{ torch: torchOn }] });
      document.getElementById('btn-torch').classList.toggle('active', torchOn);
    } catch(e) {
      statusEl.textContent = 'Could not toggle torch.';
    }
  }

  function togglePause() {
    paused = !paused;
    const btn = document.getElementById('btn-pause');
    btn.textContent = paused ? '\u25b6 Resume' : '\u23f8 Pause';
    if (paused) {
      document.body.classList.remove('scanning');
      statusEl.textContent = 'Paused.';
    } else {
      document.body.classList.add('scanning');
      statusEl.textContent = 'Scanning';
    }
  }

  // OCR loop
  function startOCRLoop() {
    if (ocrInterval) clearInterval(ocrInterval);
    ocrInterval = setInterval(readDigits, 2200);
    readDigits();
  }

  async function readDigits() {
    if (processing || paused) return;
    if (!video.videoWidth || video.readyState < 2) return;
    processing = true;

    try {
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);

      // Greyscale improves Tesseract on coloured LED/LCD displays
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const d = imageData.data;
      for (let i = 0; i < d.length; i += 4) {
        const g = d[i] * 0.299 + d[i+1] * 0.587 + d[i+2] * 0.114;
        d[i] = d[i+1] = d[i+2] = g;
      }
      ctx.putImageData(imageData, 0, 0);

      const result = await Tesseract.recognize(canvas, 'eng', {
        tessedit_char_whitelist: '0123456789.',
        tessedit_pageseg_mode: '11'  // SPARSE_TEXT — best for isolated numbers
      });

      const text = result.data.text.trim();
      outputEl.textContent = text || '—';

      syncSizes();
      ctxOv.clearRect(0, 0, overlay.width, overlay.height);
      boxes = [];

      const scaleX = overlay.width  / canvas.width;
      const scaleY = overlay.height / canvas.height;

      (result.data.words || []).forEach(word => {
        const wText = word.text.trim();
        if (!/^[0-9.]+$/.test(wText)) return;
        const { x0, y0, x1, y1 } = word.bbox;
        const sx = x0 * scaleX, sy = y0 * scaleY;
        const sw = (x1 - x0) * scaleX, sh = (y1 - y0) * scaleY;
        boxes.push({ text: wText, x: sx, y: sy, width: sw, height: sh });
        ctxOv.strokeStyle = '#00ff88';
        ctxOv.lineWidth   = 2;
        ctxOv.strokeRect(sx, sy, sw, sh);
        ctxOv.fillStyle   = '#00ff88';
        ctxOv.font        = '13px Courier New';
        ctxOv.fillText(wText, sx + 2, sy > 16 ? sy - 4 : sy + sh + 14);
      });

      statusEl.textContent = boxes.length
        ? boxes.length + ' number' + (boxes.length > 1 ? 's' : '') + ' found — tap to select'
        : 'Scanning';

    } catch(e) {
      console.error(e);
      statusEl.textContent = 'OCR error — retrying';
    }

    processing = false;
  }

  // Tap / touch to select a bounding box
  function handleTap(clientX, clientY) {
    const rect = overlay.getBoundingClientRect();
    const x = clientX - rect.left;
    const y = clientY - rect.top;
    let hit = false;
    boxes.forEach(box => {
      if (x >= box.x && x <= box.x + box.width &&
          y >= box.y && y <= box.y + box.height) {
        selectedEl.textContent = '\u25ba Selected: ' + box.text;
        ctxOv.strokeStyle = '#ffff00';
        ctxOv.lineWidth   = 3;
        ctxOv.strokeRect(box.x, box.y, box.width, box.height);
        setTimeout(() => {
          ctxOv.strokeStyle = '#00ff88';
          ctxOv.lineWidth   = 2;
          ctxOv.strokeRect(box.x, box.y, box.width, box.height);
        }, 350);
        hit = true;
      }
    });
    if (!hit) selectedEl.textContent = '';
  }

  overlay.addEventListener('click', e => handleTap(e.clientX, e.clientY));
  overlay.addEventListener('touchend', e => {
    e.preventDefault();
    const t = e.changedTouches[0];
    handleTap(t.clientX, t.clientY);
  }, { passive: false });

  window.addEventListener('resize', () => {
    if (!started) return;
    syncSizes();
    ctxOv.clearRect(0, 0, overlay.width, overlay.height);
    boxes = [];
  });

  // startCamera() is NOT auto-called — it needs a real user gesture.
</script>
</body>
</html>
